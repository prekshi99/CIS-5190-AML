{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNvU-gkptniQ"
      },
      "source": [
        "# Load Libraries and Download Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTUZTfzQwZGM",
        "outputId": "79b1c3a5-0487-47d8-87d2-897969cfa0e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.1.0+cu118)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4131 sha256=0ce49a0b3122a20cd2b4b27398e1f1d9324be2a05270e3c98d276db351983ae5\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hURtCSRNHYWx",
        "outputId": "6ba5f73d-bacb-4784-f136-d4f03fc02a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.6\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m51.2/64.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (1.16.0)\n",
            "Collecting sentencepiece (from torchtext==0.6)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6) (1.3.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.16.0\n",
            "    Uninstalling torchtext-0.16.0:\n",
            "      Successfully uninstalled torchtext-0.16.0\n",
            "Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H65qQ31cz3_m"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "from torchviz import make_dot\n",
        "from torchsummary import summary\n",
        "\n",
        "from torchtext.data import Field, TabularDataset, BucketIterator, Iterator, LabelField, TabularDataset\n",
        "\n",
        "import copy\n",
        "import gc\n",
        "import random\n",
        "import sys\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "\n",
        "\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a55HpmrniFju",
        "outputId": "eb1887d0-fb78-4547-8fff-5c3e608cc88f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mut7eaOtiHWE",
        "outputId": "afa37c67-c520-4747-8d74-bad7f3baae8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        }
      ],
      "source": [
        "# IMDB REVIEWS\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "jmqh1TLllaDT",
        "outputId": "ced535fa-5b8c-4eb6-a0be-cf0e24c063e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-summary\n",
            "  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: torch-summary\n",
            "Successfully installed torch-summary-1.4.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchsummary"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YOzXOOIiJO3",
        "outputId": "b8c58d22-65b3-4a4d-8264-bf639b702fe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So8Fi7L7iLCt",
        "outputId": "188f37a6-3ed7-4d68-9a93-671fc96aba1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Applied Machine Learning/Project Milestone 2/IMDB Dataset.csv.zip\n",
            "  inflating: IMDB Dataset.csv        \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/drive/MyDrive/Applied Machine Learning/Project Milestone 2/IMDB Dataset.csv.zip\"\n",
        "# !unzip \"/content/drive/MyDrive/Applied Machine Learning/Project Milestone 2/glove.6B.50d.txt.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SON3QHWKiS2Y"
      },
      "outputs": [],
      "source": [
        "reviews_df = pd.read_csv('/content/IMDB Dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OugvGw-1iVSW",
        "outputId": "e7c636a7-1943-4fe8-dcee-88680756fe80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6629     H.O.T.S. is proof that at one time, the movie ...\n",
            "13403    I gave this a 10 because it's the best film of...\n",
            "14497    \b\b\b\bA Turkish Bath sequence in a film noir loc...\n",
            "18844    Hello Playmates.I recently watched this film f...\n",
            "Name: review, dtype: object\n",
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ],
      "source": [
        "filtered_reviews = reviews_df[reviews_df['review'].str.contains('Playmates')]\n",
        "print(filtered_reviews['review'])\n",
        "print(string.punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67GyqTb1tWBh"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viVoMciRiXKb"
      },
      "outputs": [],
      "source": [
        "# Preprocessing\n",
        "\n",
        "def clean_string(x):\n",
        "    # remove punctuations\n",
        "    x = ''.join(' ' if char in string.punctuation else char for char in x) # replacing with a space because some reviews have no space after punctuation \"I.like\"\n",
        "    x = re.sub('[^a-zA-Z0-9]', ' ', x) # remove non-alpha numeric\n",
        "    x = re.sub('\\s+', ' ', x) # remove more than one spaces\n",
        "    x = x.lower().strip() # lower case trailing leading spaces\n",
        "    return x\n",
        "\n",
        "def remove_html_tags(x): # using regex misses cases like '&nsbm' or anchor tags like <a title=\">\">, lxml has <p> tag problem\n",
        "  x = BeautifulSoup(x, \"lxml\").text\n",
        "  return x\n",
        "\n",
        "def remove_stopwords(x):\n",
        "    stopwords_set = set(stopwords.words('english'))\n",
        "    words = x.split()\n",
        "    filtered_words = [word for word in words if word.lower() not in stopwords_set]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "def lemmatization(x):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  words = x.split()\n",
        "  lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "  lemmatized_sentence = ' '.join(lemmatized_words)\n",
        "  return lemmatized_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlR_nCGNilPG",
        "outputId": "427ba7cb-9a2e-4c00-c948-4d642933f122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-1c94d9d519d6>:12: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  x = BeautifulSoup(x, \"lxml\").text\n"
          ]
        }
      ],
      "source": [
        "reviews_df_cleaned = reviews_df.copy()\n",
        "reviews_df_cleaned['review'] = reviews_df['review'].apply(remove_html_tags)\n",
        "reviews_df_cleaned['review'] = reviews_df_cleaned['review'].apply(clean_string)\n",
        "reviews_df_cleaned['review'] = reviews_df_cleaned['review'].apply(remove_stopwords)\n",
        "reviews_df_cleaned['review'] = reviews_df_cleaned['review'].apply(lemmatization)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_to_integer(x):\n",
        "    if x == 'positive':\n",
        "        return 1\n",
        "    elif x == 'negative':\n",
        "        return 0\n",
        "\n",
        "reviews_df_cleaned['sentiment'] = reviews_df_cleaned['sentiment'].apply(sentiment_to_integer)\n",
        "# print(reviews_df_cleaned)\n",
        "# positive_reviews_count = reviews_df_cleaned[reviews_df_cleaned['sentiment'] == 1]['review'].count()\n",
        "# # print(positive_reviews_count)\n",
        "# negative_reviews_count = reviews_df[reviews_df_cleaned['sentiment'] == 0]['review'].count()\n",
        "# negative_reviews_count"
      ],
      "metadata": {
        "id": "7ODMcZZKCzUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Preprocessed Dataset back to a CSV file"
      ],
      "metadata": {
        "id": "fgPrTcT7A4ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_df_cleaned.to_csv('/content/drive/MyDrive/Applied Machine Learning/Project Milestone 2/IMDBReviewsCleaned.csv', index=False)"
      ],
      "metadata": {
        "id": "Su1d3o5hA3qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_df_cleaned = pd.read_csv('/content/drive/MyDrive/Applied Machine Learning/Project Milestone 2/IMDBReviewsCleaned.csv')\n",
        "\n",
        "reviews_df_cleaned"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "D_iC1MiaCXCg",
        "outputId": "77bbbbd1-ce1e-434d-f57f-143cc0d51990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review  sentiment\n",
              "0      one reviewer mentioned watching 1 oz episode h...          1\n",
              "1      wonderful little production filming technique ...          1\n",
              "2      thought wonderful way spend time hot summer we...          1\n",
              "3      basically family little boy jake think zombie ...          0\n",
              "4      petter mattei love time money visually stunnin...          1\n",
              "...                                                  ...        ...\n",
              "49995  thought movie right good job creative original...          1\n",
              "49996  bad plot bad dialogue bad acting idiotic direc...          0\n",
              "49997  catholic taught parochial elementary school nu...          0\n",
              "49998  going disagree previous comment side maltin on...          0\n",
              "49999  one expects star trek movie high art fan expec...          0\n",
              "\n",
              "[50000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3c226f5-b15f-470c-8e9a-2a961afb60be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one reviewer mentioned watching 1 oz episode h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wonderful little production filming technique ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically family little boy jake think zombie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei love time money visually stunnin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>thought movie right good job creative original...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>catholic taught parochial elementary school nu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>going disagree previous comment side maltin on...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>one expects star trek movie high art fan expec...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3c226f5-b15f-470c-8e9a-2a961afb60be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c3c226f5-b15f-470c-8e9a-2a961afb60be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c3c226f5-b15f-470c-8e9a-2a961afb60be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-69d96d85-87ad-43c2-b843-9f76be58fcc7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-69d96d85-87ad-43c2-b843-9f76be58fcc7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-69d96d85-87ad-43c2-b843-9f76be58fcc7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfEsRUWltf3Z"
      },
      "source": [
        "# Dataset Preparation before inputting  to RNN (Torchtext)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eOl5J79i1RU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33d2dceb-a856-426f-890a-aaf89f6dd6bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "# https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html\n",
        "# https://torchtext.readthedocs.io/en/latest/data.html\n",
        "\n",
        "! pip install spacy\n",
        "# to use tokenizer from known NLP library spacy -> efficeint for large datasets compared to traditional python methods + more robust.\n",
        "# also provides support for tokenization in languages other than english."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python -m spacy download en_core_web_sm # downloading the english vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCAmRq_NDWuM",
        "outputId": "51d01c79-95c4-4934-a0d5-d3db3749b8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-01 17:33:05.180441: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-01 17:33:05.180511: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-01 17:33:05.180564: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-01 17:33:05.195215: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-01 17:33:06.917797: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text and label formatting\n",
        "\n",
        "# TEXT will be our feature/token\n",
        "\n",
        "TEXT = Field(\n",
        "    tokenize='spacy',\n",
        "    tokenizer_language='en_core_web_sm'\n",
        ")\n",
        "\n",
        "LABEL = LabelField(dtype=torch.long)\n",
        "print(TEXT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS_FGNLNDinP",
        "outputId": "1da7274b-2f4e-4b37-d300-d919928d1f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torchtext.data.field.Field object at 0x7d7995951d80>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_data = TabularDataset(\n",
        "    path='/content/drive/MyDrive/Applied Machine Learning/Project Milestone 2/IMDBReviewsCleaned.csv', format='csv',\n",
        "    skip_header = True, fields=[('review', TEXT), ('sentiment', LABEL)]\n",
        ")"
      ],
      "metadata": {
        "id": "oCgVHMohJngR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vars(parsed_data.examples[0])"
      ],
      "metadata": {
        "id": "tGyvmswkclyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Validation Split"
      ],
      "metadata": {
        "id": "JliFItSyJ7RS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pytorch.org/text/_modules/torchtext/data/dataset.html\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "train_ratio = 0.75\n",
        "val_ratio = 0.125\n",
        "test_ratio = 0.125\n",
        "\n",
        "\n",
        "train_data, val_data, test_data = parsed_data.split(\n",
        "    split_ratio=[train_ratio, val_ratio, test_ratio],\n",
        "    stratified=True,  # distribution of labels is maintained in each split\n",
        "    strata_field='sentiment',  # field used for stratification\n",
        "    random_state=random.getstate()\n",
        ")\n",
        "\n",
        "print(f\"Number of training examples: {len(train_data)}\")\n",
        "print(f\"Number of validation examples: {len(val_data)}\")\n",
        "print(f\"Number of test examples: {len(test_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lK3-VFiJ6Ip",
        "outputId": "115011de-19e6-4468-c22d-9d339a122f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 37500\n",
            "Number of validation examples: 6250\n",
            "Number of test examples: 6250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd1IHZAxLZhG",
        "outputId": "f6ea386b-b094-4e17-94d6-42c8c233b269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'review': ['show', 'drive', 'crazy', 'go', 'everything', 'family', 'even', 'intended', 'comedy', 'show', 'suppose', 'follow', 'dave', 'vicky', 'gold', 'michael', 'rapaport', 'anita', 'barone', 'raise', 'three', 'teenage', 'child', 'hilary', 'larry', 'mike', 'good', 'premise', 'comedy', 'yes', 'mean', 'good', 'show', 'think', 'ever', 'heard', 'cruder', 'talk', 'parent', 'child', 'vice', 'versa', 'talk', 'seems', 'show', 'control', 'child', 'parent', 'sex', 'know', 'sexual', 'intercourse', 'usually', 'subject', 'talked', 'teenager', 'often', 'brought', 'nearly', 'every', 'episode', 'point', 'one', 'episode', 'watching', 'involved', 'parent', 'giving', 'daughter', 'hilary', 'car', 'think', 'related', 'anyway', 'way', 'talk', 'parent', 'talk', 'hilary', 'like', 'slave', 'show', 'fails', 'comedy', 'level', 'laughed', 'show', 'numerous', 'time', 'attempted', 'watch', 'person', 'gave', 'film', 'animal', 'house', 'dumb', 'dumber', 'high', 'mark', 'michael', 'rapaport', 'good', 'actor', 'choose', 'ruin', 'career', 'making', 'piece', 'filth', 'show', 'beyond', 'parent', 'make', 'sure', 'child', 'never', 'mean', 'never', 'watch', 'teenager', 'probably', 'get', 'laugh', 'blatant', 'sexual', 'reference', 'nothing', 'come', 'afterwards', 'feel', 'rather', 'empty', '1', '1', '2', '5', 'star'], 'sentiment': '0'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparams"
      ],
      "metadata": {
        "id": "KGzbdaGJ_N5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 20000\n",
        "# learning_rate = 0.01\n",
        "# learning_rate = 0.001\n",
        "learning_rate = 0.0005\n",
        "batch_size = 64\n",
        "# num_epochs = 15\n",
        "num_epochs = 5\n",
        "device = torch.device('cuda')\n",
        "\n",
        "embedding_dim = 25\n",
        "# embeddings = 50 that use glove\n",
        "# hidden_dim = 16\n",
        "hidden_dim = 8\n",
        "# dropout_prob = 0.6\n",
        "dropout_prob = 0.2\n",
        "weight_decay = 1e-4\n",
        "num_classes = 2"
      ],
      "metadata": {
        "id": "dJjK0SAW_Mzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total models = 3(lr) * 2(epochs) * 2(embedding) * 2(hidden_dim) * 2(dropout_prob) * 2(optimizers) * 3(datasets) = 288 models"
      ],
      "metadata": {
        "id": "x2kIMYhKaZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vocabulary"
      ],
      "metadata": {
        "id": "SlNh4d36NoZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train_data, max_size=vocab_size, vectors=\"glove.6B.50d\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iosxtfgsVONZ",
        "outputId": "68242123-b9af-439c-dfa4-f5ce0c04b67f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.41MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:19<00:00, 20711.25it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train_data, max_size=vocab_size) # only on training data\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(f'Vocab Size {len(TEXT.vocab)}') # 2002 with <unk> and <pad> tokens\n",
        "print(f'Label Size {len(LABEL.vocab)}')\n",
        "print(TEXT.vocab.freqs.most_common(20))\n",
        "\n",
        "# RNN can handle arbitrary lenghts but padding is rewuired for padding sequences to same length in\n",
        "# a given minibatch so we can store those in an array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZb_gVjANrhZ",
        "outputId": "4929d5e6-5c44-4e25-bdcf-68a114a91290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab Size 20002\n",
            "Label Size 2\n",
            "[('movie', 76850), ('film', 69759), ('one', 41390), ('like', 30748), ('time', 23478), ('good', 22353), ('character', 21165), ('story', 18864), ('even', 18490), ('get', 18362), ('would', 18270), ('make', 18165), ('see', 17974), ('really', 17302), ('well', 16004), ('scene', 15955), ('much', 14440), ('bad', 13843), ('people', 13628), ('great', 13528)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(TEXT.vocab.itos[:10]) # tokens for first 10 elements"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVO8lhZvPAnx",
        "outputId": "3fe79f5b-0aff-4516-f84e-108582cfbab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<pad>', 'movie', 'film', 'one', 'like', 'time', 'good', 'character', 'story']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(TEXT.vocab.stoi['movie'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNReqsRZPFGL",
        "outputId": "6ef4c14f-de6e-4a74-efef-8b04b317d8dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloaders (without dataset shift)\n",
        "\n"
      ],
      "metadata": {
        "id": "fRt8LyyvPsqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BucketIterator will group batches such that sentences have similar lenght and reduces number of padding required.\n",
        "# Having batches with similar length examples provides a lot of gain for recurrent models (RNN, GRU, LSTM)\n",
        "# and transformers models (bert, roBerta, gpt2, xlnet, etc.) where padding will be minimal.\n",
        "\n",
        "# https://gmihaila.github.io/tutorial_notebooks/pytorchtext_bucketiterator/\n",
        "\n",
        "train_loader, val_loader, test_loader = BucketIterator.splits(\n",
        "    (train_data, val_data, test_data),\n",
        "    batch_size=batch_size,\n",
        "    sort_within_batch=True,\n",
        "    sort_key=lambda x: len(x.review),\n",
        "    sort = False,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "BmCTPtciPpv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_loader:\n",
        "  print(batch.review.size())\n",
        "  print(batch.sentiment.size())\n",
        "  break\n",
        "\n",
        "for batch in val_loader:\n",
        "  print(batch.review.size())\n",
        "  print(batch.sentiment.size())\n",
        "  break\n",
        "\n",
        "for batch in test_loader:\n",
        "  print(batch.review.size())\n",
        "  print(batch.sentiment.size())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "0QOcz3t8R6Px",
        "outputId": "6067a18a-6515-4819-9542-d46994937286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-437f2b078982>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, device)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m    236\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[0;34m(self, arr, device)\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloaders with Dataset Shift"
      ],
      "metadata": {
        "id": "JRbaJT1XiXi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_shift(X, mean = None, std = None):\n",
        "  lst = list()\n",
        "  for i in range(len(X)):\n",
        "    lst.append(len(X[i].split()))\n",
        "  lst = np.array(lst)\n",
        "  if mean is None:\n",
        "    mean = np.mean(lst)\n",
        "  if std is None:\n",
        "    std = np.std(lst)\n",
        "  len_short = round(mean - 1 / 3 * std)\n",
        "  len_long = round(mean + 1 / 3 * std)\n",
        "  X_short = list()\n",
        "  X_long = list()\n",
        "  for doc in X:\n",
        "    document = doc.split()\n",
        "    if len(document) < len_short:\n",
        "      while len(document) != len_short:\n",
        "        document.append('<PAD>')\n",
        "      X_short.append(document)\n",
        "    else:\n",
        "      X_short.append(document[:len_short])\n",
        "    document = doc.split()\n",
        "    if len(document) < len_long:\n",
        "      while len(document) != len_long:\n",
        "        document.append('<PAD>')\n",
        "      X_long.append(document)\n",
        "    else:\n",
        "      X_long.append(document[:len_long])\n",
        "  return np.array(X_short), np.array(X_long), mean, std"
      ],
      "metadata": {
        "id": "AhiJjSKiib3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data import Example, Field, TabularDataset, BucketIterator, Dataset\n",
        "\n",
        "def create_datasets_loaders(data, batch_size, device, mean=None, std=None):\n",
        "    texts = [' '.join(example.review) for example in data.dataset.examples]\n",
        "    X_short, X_long, mean, std = dataset_shift(texts, mean, std)\n",
        "\n",
        "    fields = [('review', TEXT), ('sentiment', LABEL)]\n",
        "    examples_short = [Example.fromlist([X_short[i], example.sentiment], fields) for i, example in enumerate(data.dataset.examples)]\n",
        "    examples_long = [Example.fromlist([X_long[i], example.sentiment], fields) for i, example in enumerate(data.dataset.examples)]\n",
        "\n",
        "    dataset_short = Dataset(examples=examples_short, fields=fields)\n",
        "    dataset_long = Dataset(examples=examples_long, fields=fields)\n",
        "\n",
        "    loader_short, loader_long = BucketIterator.splits(\n",
        "        (dataset_short, dataset_long),\n",
        "        batch_size=batch_size,\n",
        "        sort_within_batch=True,\n",
        "        sort_key=lambda x: len(x.review),\n",
        "        sort = False,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    return loader_short, loader_long, mean, std"
      ],
      "metadata": {
        "id": "uyjhuyQMiwJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_short, train_loader_long, mean, std = create_datasets_loaders(train_loader, batch_size, device)"
      ],
      "metadata": {
        "id": "6BkEfUYei8gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(next(iter(train_loader)).review[0])\n",
        "print(next(iter(train_loader_short)).review[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZFw_u4Go2IS",
        "outputId": "f481996f-1006-4e19-9373-5f0ae1083761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 146,  410,   16,  444,   23,  118,  544,   67,    4,    2,   16,   29,\n",
            "          10, 6799,  220,   21,  220, 6079,  310,  555,  101,   23,    4,  118,\n",
            "         315,  178,  118,  670,    4,   15,  486, 2230,  707,  670, 6820,    2,\n",
            "         317,  691,    3, 7574,   19,  613,    2,    0,  275, 1399,  571, 5353,\n",
            "        2905, 2975,   44,  294, 2283,   41,  106,   46,    2,  118,  334, 2933,\n",
            "           2,    2, 1674,    2], device='cuda:0')\n",
            "tensor([  874,  3267,   106,     4,   637,   453,    24,  6590,     2,   118,\n",
            "         3706,   817,  6540,  1269,  5196,   185,    73,  1220,   742,     2,\n",
            "         1557,  4078,     4,   787,    21,  9201,  1188,     7,    39,   278,\n",
            "          317,   324,  5038,     4,  6994,    38,    95,     4,   278,   721,\n",
            "            2,  1837, 14568,     2,    36,   366,    20,   118,     4,  2877,\n",
            "            2,   133,    89,   113,   686,    29,  3075,     6,  1677,    93,\n",
            "            4,   280,  2179,   342], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader_short, val_loader_long, _, _ = create_datasets_loaders(val_loader, batch_size, device, mean, std)"
      ],
      "metadata": {
        "id": "2uSYIfs4mSao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader_short, test_loader_long, _, _  = create_datasets_loaders(test_loader, batch_size, device, mean, std)"
      ],
      "metadata": {
        "id": "ie4OwzaLmT-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "pBfmZ9kY_Zvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DL Model Architecture for IMDB Reviews Classification\n",
        "# https://sebastianraschka.com/pdf/lecture-notes/stat453ss21/L15_intro-rnn__slides.pdf --> slide 29 - 47\n",
        "\n",
        "# https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "\n",
        "\n",
        "\n",
        "class SentimentAnalysis(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, dropout_prob=0.5, use_glove = False):\n",
        "        super(SentimentAnalysis, self).__init__()\n",
        "\n",
        "        # embedding layer --> input tokens to vectors\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        if use_glove:\n",
        "          self.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
        "\n",
        "        # self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "        # LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
        "\n",
        "        # dropout layer --> prevent overfitting\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "        # self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        # fc\n",
        "        self.fc_hidden = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        # output layer for final classification\n",
        "        self.fc_output = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, text): # [sentence_length, batch_size]\n",
        "        embedded = self.embedding(text) # in embedding matrix: [sentence_length (rows), batch_size (columns), dimension of hidden layer]\n",
        "\n",
        "        output, (hn, _) = self.lstm(embedded) # one lstm will output y, hidden state for next layer\n",
        "\n",
        "        hn = self.dropout(hn) # using dropout for regularization\n",
        "\n",
        "        # output from the last timestep to get context of the entire sequence\n",
        "        last_hidden = (hn[0] + hn[1]) / 2\n",
        "        # last_hidden = hn\n",
        "        last_hidden.squeeze_(0) # so that we can send it to the linear layer ahead.\n",
        "        # instead of taking final output from LSTM we are taking the last hidden layer and applying our own output function which is fc + relu\n",
        "\n",
        "        hidden_output = F.relu(self.dropout(self.fc_hidden(last_hidden)))\n",
        "\n",
        "        final_output = self.fc_output(hidden_output)\n",
        "        return final_output"
      ],
      "metadata": {
        "id": "qTxhAhdbtVLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(TEXT.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBX5dstHedDX",
        "outputId": "5cc719aa-ad30-4ddc-bbe6-3f90e30e2a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20002"
            ]
          },
          "metadata": {},
          "execution_count": 372
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Initialization"
      ],
      "metadata": {
        "id": "xyTtJnaHj35L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model = SentimentAnalysis(input_dim = len(TEXT.vocab),\n",
        "                          embedding_dim=embedding_dim,\n",
        "                          hidden_dim=hidden_dim,\n",
        "                          output_dim=num_classes,\n",
        "                          dropout_prob = dropout_prob,\n",
        "                          use_glove = True\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "D8hwLptqzKWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # @title Testing model Initialization\n",
        "# variable_name = \"\"\n",
        "# variable_name = \"\"\n",
        "# y_hat = model(torch.Tensor([[1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]]).to(torch.long).to(device))"
      ],
      "metadata": {
        "id": "D3I_8Pkuw_wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_hat"
      ],
      "metadata": {
        "id": "LVvhE6OD0RXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make_dot(y_hat, params=dict(list(model.named_parameters()))).render(\"rnn_torchviz\", format=\"png\")"
      ],
      "metadata": {
        "id": "kR5nZCQczhtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(model)"
      ],
      "metadata": {
        "id": "LD-SAFDdkSBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J67X1d5oHCk",
        "outputId": "5f80d450-0b7b-4a5b-c861-af0e20daf726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summary(model, (100, ), dtypes=[torch.long], verbose=2, col_width=16, col_names=[\"kernel_size\", \"output_size\", \"num_params\", \"mult_adds\"],)"
      ],
      "metadata": {
        "id": "Z4fJH2USudfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Validation Test loop"
      ],
      "metadata": {
        "id": "FGhHW7UOh2l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(model, data_loader, device):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        correct_pred, num_examples, num_batches = 0, 0, 0\n",
        "        F1 = 0\n",
        "        for i, (features, targets) in enumerate(data_loader):\n",
        "            features = features.to(device)\n",
        "            targets = targets.float().to(device)\n",
        "            logits = F.softmax(model(features), dim =1)\n",
        "            _, predicted_labels = torch.max(logits, 1)\n",
        "            num_examples += targets.size(0)\n",
        "            num_batches += 1\n",
        "            F1 += f1_score(torch.Tensor.cpu(targets), torch.Tensor.cpu(predicted_labels))\n",
        "            correct_pred += (predicted_labels == targets).sum()\n",
        "    return float(correct_pred.float()/num_examples * 100), F1 / num_batches"
      ],
      "metadata": {
        "id": "FDxOPmPDc5pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_loop_test(model, optimizer, num_epochs, device, train_loader_input, val_loader_input, test_loader_input):\n",
        "  train_loader = train_loader_input\n",
        "  val_loader = val_loader_input\n",
        "  test_loader = test_loader_input\n",
        "  train_scores = list()\n",
        "  val_scores = list()\n",
        "  train_losses = list()\n",
        "  val_losses = list()\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      loss_agg = 0\n",
        "      num_batches = 0\n",
        "      for batch_idx, batch_data in enumerate(train_loader):\n",
        "\n",
        "          text = batch_data.review.to(device)\n",
        "          labels = batch_data.sentiment.to(device)\n",
        "\n",
        "          logits = model(text)\n",
        "          loss = F.cross_entropy(logits, labels)\n",
        "          loss_agg += float(loss)\n",
        "          num_batches += 1\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # if not batch_idx % 50:\n",
        "          #     print (f'Epoch: {epoch+1}/{num_epochs}' \\\n",
        "          #           f'Batch {batch_idx}/{len(train_loader)}' \\\n",
        "          #           f'Loss: {loss}')\n",
        "\n",
        "      loss_val_agg = 0\n",
        "      num_val_batches = 0\n",
        "      for batch_idx, batch_data in enumerate(val_loader):\n",
        "\n",
        "          text = batch_data.review.to(device)\n",
        "          labels = batch_data.sentiment.to(device)\n",
        "\n",
        "          logits = model(text)\n",
        "          loss = F.cross_entropy(logits, labels)\n",
        "          loss_val_agg += float(loss)\n",
        "          num_val_batches += 1\n",
        "\n",
        "      with torch.set_grad_enabled(False):\n",
        "          print(\"Epoch:\", epoch)\n",
        "          print(f'training accuracy/f1: '\n",
        "                f'{compute_accuracy(model, train_loader, device)}'\n",
        "                f'\\nvalid accuracy/f1: '\n",
        "                f'{compute_accuracy(model, val_loader, device)}')\n",
        "          train_losses.append(loss_agg/num_batches)\n",
        "          val_losses.append(loss_val_agg / num_val_batches)\n",
        "          train_scores.append(compute_accuracy(model, val_loader, device))\n",
        "          val_scores.append(compute_accuracy(model, val_loader, device))\n",
        "\n",
        "  print(f'Test accuracy/f1: {compute_accuracy(model, test_loader, device)}')\n",
        "  return train_scores, val_scores, train_losses, val_losses"
      ],
      "metadata": {
        "id": "NZbT1cHDb632"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_loop_test(model, optimizer, num_epochs, device, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ikuvXolgufi",
        "outputId": "e2e0c497-a9ae-4b3c-8dc9-1e320ffde47d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5Batch 0/586Loss: 0.3645293414592743\n",
            "Epoch: 1/5Batch 50/586Loss: 0.372294157743454\n",
            "Epoch: 1/5Batch 100/586Loss: 0.2793301045894623\n",
            "Epoch: 1/5Batch 150/586Loss: 0.4087273180484772\n",
            "Epoch: 1/5Batch 200/586Loss: 0.49754753708839417\n",
            "Epoch: 1/5Batch 250/586Loss: 0.39730966091156006\n",
            "Epoch: 1/5Batch 300/586Loss: 0.17276531457901\n",
            "Epoch: 1/5Batch 350/586Loss: 0.4726679027080536\n",
            "Epoch: 1/5Batch 400/586Loss: 0.25318723917007446\n",
            "Epoch: 1/5Batch 450/586Loss: 0.4106673300266266\n",
            "Epoch: 1/5Batch 500/586Loss: 0.2871471345424652\n",
            "Epoch: 1/5Batch 550/586Loss: 0.4723036587238312\n",
            "training accuracy/f1: (87.68533325195312, 0.8752800091370858)\n",
            "valid accuracy/f1: (83.5199966430664, 0.8300104193801696)\n",
            "Epoch: 2/5Batch 0/586Loss: 0.32929641008377075\n",
            "Epoch: 2/5Batch 50/586Loss: 0.5541124939918518\n",
            "Epoch: 2/5Batch 100/586Loss: 0.3666008412837982\n",
            "Epoch: 2/5Batch 150/586Loss: 0.19914399087429047\n",
            "Epoch: 2/5Batch 200/586Loss: 0.2843019664287567\n",
            "Epoch: 2/5Batch 250/586Loss: 0.31596535444259644\n",
            "Epoch: 2/5Batch 300/586Loss: 0.3615626394748688\n",
            "Epoch: 2/5Batch 350/586Loss: 0.3475049138069153\n",
            "Epoch: 2/5Batch 400/586Loss: 0.3383033573627472\n",
            "Epoch: 2/5Batch 450/586Loss: 0.4651990532875061\n",
            "Epoch: 2/5Batch 500/586Loss: 0.3574402332305908\n",
            "Epoch: 2/5Batch 550/586Loss: 0.29611536860466003\n",
            "training accuracy/f1: (88.19999694824219, 0.8807575819105053)\n",
            "valid accuracy/f1: (83.8239974975586, 0.8344192786491323)\n",
            "Epoch: 3/5Batch 0/586Loss: 0.4018474817276001\n",
            "Epoch: 3/5Batch 50/586Loss: 0.3781074285507202\n",
            "Epoch: 3/5Batch 100/586Loss: 0.33173733949661255\n",
            "Epoch: 3/5Batch 150/586Loss: 0.43001478910446167\n",
            "Epoch: 3/5Batch 200/586Loss: 0.20731356739997864\n",
            "Epoch: 3/5Batch 250/586Loss: 0.2923130691051483\n",
            "Epoch: 3/5Batch 300/586Loss: 0.27385640144348145\n",
            "Epoch: 3/5Batch 350/586Loss: 0.15517523884773254\n",
            "Epoch: 3/5Batch 400/586Loss: 0.32765617966651917\n",
            "Epoch: 3/5Batch 450/586Loss: 0.3406420052051544\n",
            "Epoch: 3/5Batch 500/586Loss: 0.3961726725101471\n",
            "Epoch: 3/5Batch 550/586Loss: 0.32693278789520264\n",
            "training accuracy/f1: (88.73066711425781, 0.8856691423546861)\n",
            "valid accuracy/f1: (84.2719955444336, 0.8382134444780414)\n",
            "Epoch: 4/5Batch 0/586Loss: 0.28392285108566284\n",
            "Epoch: 4/5Batch 50/586Loss: 0.2599729001522064\n",
            "Epoch: 4/5Batch 100/586Loss: 0.3891145884990692\n",
            "Epoch: 4/5Batch 150/586Loss: 0.2763499915599823\n",
            "Epoch: 4/5Batch 200/586Loss: 0.2892351448535919\n",
            "Epoch: 4/5Batch 250/586Loss: 0.470160573720932\n",
            "Epoch: 4/5Batch 300/586Loss: 0.21271532773971558\n",
            "Epoch: 4/5Batch 350/586Loss: 0.18795324862003326\n",
            "Epoch: 4/5Batch 400/586Loss: 0.32531997561454773\n",
            "Epoch: 4/5Batch 450/586Loss: 0.2508503794670105\n",
            "Epoch: 4/5Batch 500/586Loss: 0.5833256244659424\n",
            "Epoch: 4/5Batch 550/586Loss: 0.3068530261516571\n",
            "training accuracy/f1: (89.1919937133789, 0.8901877069827966)\n",
            "valid accuracy/f1: (84.43199920654297, 0.8406875235881371)\n",
            "Epoch: 5/5Batch 0/586Loss: 0.44058749079704285\n",
            "Epoch: 5/5Batch 50/586Loss: 0.16529910266399384\n",
            "Epoch: 5/5Batch 100/586Loss: 0.33401644229888916\n",
            "Epoch: 5/5Batch 150/586Loss: 0.2911219894886017\n",
            "Epoch: 5/5Batch 200/586Loss: 0.2737259864807129\n",
            "Epoch: 5/5Batch 250/586Loss: 0.26021304726600647\n",
            "Epoch: 5/5Batch 300/586Loss: 0.3960183262825012\n",
            "Epoch: 5/5Batch 350/586Loss: 0.24846789240837097\n",
            "Epoch: 5/5Batch 400/586Loss: 0.3183634877204895\n",
            "Epoch: 5/5Batch 450/586Loss: 0.2593000531196594\n",
            "Epoch: 5/5Batch 500/586Loss: 0.34182214736938477\n",
            "Epoch: 5/5Batch 550/586Loss: 0.16695182025432587\n",
            "training accuracy/f1: (89.61332702636719, 0.8944359717126512)\n",
            "valid accuracy/f1: (84.51199340820312, 0.8399678753659865)\n",
            "Test accuracy/f1: (84.7040023803711, 0.8419523498171246)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([{(83.40799713134766, 0.8287931488519693)},\n",
              "  {(83.5199966430664, 0.830841816427097)},\n",
              "  {(83.95199584960938, 0.835247385721201)},\n",
              "  {(84.23999786376953, 0.8385139322752947)},\n",
              "  {(84.31999969482422, 0.8379940743056159)}],\n",
              " [{(83.32799530029297, 0.8280974588752512)},\n",
              "  {(83.9679946899414, 0.8355230857504318)},\n",
              "  {(84.2719955444336, 0.8378761983499856)},\n",
              "  {(83.76000213623047, 0.8341326129438777)},\n",
              "  {(84.60800170898438, 0.8397523455152802)}],\n",
              " [0.3372415368772611,\n",
              "  0.32702942187468753,\n",
              "  0.318907448329006,\n",
              "  0.30303007299430135,\n",
              "  0.2964557493963746],\n",
              " [0.4056741069166028,\n",
              "  0.4095482724357624,\n",
              "  0.4072017925126212,\n",
              "  0.3974202989923711,\n",
              "  0.3976640076357491])"
            ]
          },
          "metadata": {},
          "execution_count": 386
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_loop_test(train_loader_short, val_loader_short, test_loader_short)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVYej7gQrREa",
        "outputId": "612b1a0f-94f3-4af3-9f2f-c74121b6535a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5Batch 0/586Loss: 0.6931326985359192\n",
            "Epoch: 1/5Batch 50/586Loss: 0.6891793608665466\n",
            "Epoch: 1/5Batch 100/586Loss: 0.6736785173416138\n",
            "Epoch: 1/5Batch 150/586Loss: 0.5976961255073547\n",
            "Epoch: 1/5Batch 200/586Loss: 0.5359525084495544\n",
            "Epoch: 1/5Batch 250/586Loss: 0.44365987181663513\n",
            "Epoch: 1/5Batch 300/586Loss: 0.5402395129203796\n",
            "Epoch: 1/5Batch 350/586Loss: 0.49689117074012756\n",
            "Epoch: 1/5Batch 400/586Loss: 0.4443376660346985\n",
            "Epoch: 1/5Batch 450/586Loss: 0.363057941198349\n",
            "Epoch: 1/5Batch 500/586Loss: 0.45249223709106445\n",
            "Epoch: 1/5Batch 550/586Loss: 0.32229888439178467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-260-bb6b16c7e67c>:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  logits = F.softmax(model(features))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training accuracy: 80.44%\n",
            "valid accuracy: 77.23%\n",
            "Epoch: 2/5Batch 0/586Loss: 0.3973460793495178\n",
            "Epoch: 2/5Batch 50/586Loss: 0.3935859203338623\n",
            "Epoch: 2/5Batch 100/586Loss: 0.38213157653808594\n",
            "Epoch: 2/5Batch 150/586Loss: 0.302183598279953\n",
            "Epoch: 2/5Batch 200/586Loss: 0.41224390268325806\n",
            "Epoch: 2/5Batch 250/586Loss: 0.41908887028694153\n",
            "Epoch: 2/5Batch 300/586Loss: 0.2709755301475525\n",
            "Epoch: 2/5Batch 350/586Loss: 0.38980206847190857\n",
            "Epoch: 2/5Batch 400/586Loss: 0.360057532787323\n",
            "Epoch: 2/5Batch 450/586Loss: 0.29168763756752014\n",
            "Epoch: 2/5Batch 500/586Loss: 0.365852415561676\n",
            "Epoch: 2/5Batch 550/586Loss: 0.43530890345573425\n",
            "training accuracy: 90.05%\n",
            "valid accuracy: 83.95%\n",
            "Epoch: 3/5Batch 0/586Loss: 0.20116202533245087\n",
            "Epoch: 3/5Batch 50/586Loss: 0.1717316210269928\n",
            "Epoch: 3/5Batch 100/586Loss: 0.22574712336063385\n",
            "Epoch: 3/5Batch 150/586Loss: 0.31779220700263977\n",
            "Epoch: 3/5Batch 200/586Loss: 0.25272613763809204\n",
            "Epoch: 3/5Batch 250/586Loss: 0.24847163259983063\n",
            "Epoch: 3/5Batch 300/586Loss: 0.16612805426120758\n",
            "Epoch: 3/5Batch 350/586Loss: 0.30444127321243286\n",
            "Epoch: 3/5Batch 400/586Loss: 0.2529180645942688\n",
            "Epoch: 3/5Batch 450/586Loss: 0.353197306394577\n",
            "Epoch: 3/5Batch 500/586Loss: 0.3887532353401184\n",
            "Epoch: 3/5Batch 550/586Loss: 0.19812721014022827\n",
            "training accuracy: 94.66%\n",
            "valid accuracy: 84.11%\n",
            "Epoch: 4/5Batch 0/586Loss: 0.2393716275691986\n",
            "Epoch: 4/5Batch 50/586Loss: 0.20011040568351746\n",
            "Epoch: 4/5Batch 100/586Loss: 0.10632926970720291\n",
            "Epoch: 4/5Batch 150/586Loss: 0.15852682292461395\n",
            "Epoch: 4/5Batch 200/586Loss: 0.08046790957450867\n",
            "Epoch: 4/5Batch 250/586Loss: 0.20220516622066498\n",
            "Epoch: 4/5Batch 300/586Loss: 0.09184283763170242\n",
            "Epoch: 4/5Batch 350/586Loss: 0.24370978772640228\n",
            "Epoch: 4/5Batch 400/586Loss: 0.1390165388584137\n",
            "Epoch: 4/5Batch 450/586Loss: 0.20542901754379272\n",
            "Epoch: 4/5Batch 500/586Loss: 0.15187259018421173\n",
            "Epoch: 4/5Batch 550/586Loss: 0.128748819231987\n",
            "training accuracy: 97.42%\n",
            "valid accuracy: 84.67%\n",
            "Epoch: 5/5Batch 0/586Loss: 0.0653659999370575\n",
            "Epoch: 5/5Batch 50/586Loss: 0.10530329495668411\n",
            "Epoch: 5/5Batch 100/586Loss: 0.07767129689455032\n",
            "Epoch: 5/5Batch 150/586Loss: 0.04225004464387894\n",
            "Epoch: 5/5Batch 200/586Loss: 0.16145606338977814\n",
            "Epoch: 5/5Batch 250/586Loss: 0.10611318796873093\n",
            "Epoch: 5/5Batch 300/586Loss: 0.0792664885520935\n",
            "Epoch: 5/5Batch 350/586Loss: 0.17797192931175232\n",
            "Epoch: 5/5Batch 400/586Loss: 0.07192093133926392\n",
            "Epoch: 5/5Batch 450/586Loss: 0.2444731742143631\n",
            "Epoch: 5/5Batch 500/586Loss: 0.06624685972929001\n",
            "Epoch: 5/5Batch 550/586Loss: 0.0514909029006958\n",
            "training accuracy: 98.39%\n",
            "valid accuracy: 84.34%\n",
            "Test accuracy: 84.24%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_loop_test(train_loader_long, val_loader_long, test_loader_long)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOZaFF8FrdD1",
        "outputId": "a7398c3e-d09f-4103-dd27-4cba0501b52f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15Batch 0/586Loss: 0.6312860250473022\n",
            "Epoch: 1/15Batch 50/586Loss: 3.78112389398666e-07\n",
            "Epoch: 1/15Batch 100/586Loss: 0.0\n",
            "Epoch: 1/15Batch 150/586Loss: 0.0\n",
            "Epoch: 1/15Batch 200/586Loss: 0.0\n",
            "Epoch: 1/15Batch 250/586Loss: 0.0\n",
            "Epoch: 1/15Batch 300/586Loss: 0.0024969736114144325\n",
            "Epoch: 1/15Batch 350/586Loss: 2.9243426524772076e-07\n",
            "Epoch: 1/15Batch 400/586Loss: 2.4864978058758425e-06\n",
            "Epoch: 1/15Batch 450/586Loss: 8.772855153438286e-07\n",
            "Epoch: 1/15Batch 500/586Loss: 4.656610741449185e-08\n",
            "Epoch: 1/15Batch 550/586Loss: 2.738073590080603e-07\n",
            "training accuracy: 50.00%\n",
            "valid accuracy: 50.00%\n",
            "Epoch: 2/15Batch 0/586Loss: 20.41591453552246\n",
            "Epoch: 2/15Batch 50/586Loss: 0.0\n",
            "Epoch: 2/15Batch 100/586Loss: 0.0\n",
            "Epoch: 2/15Batch 150/586Loss: 1.8626450382086546e-09\n",
            "Epoch: 2/15Batch 200/586Loss: 0.0\n",
            "Epoch: 2/15Batch 250/586Loss: 0.0\n",
            "Epoch: 2/15Batch 300/586Loss: 3.494354486465454\n",
            "Epoch: 2/15Batch 350/586Loss: 9.804492037801538e-06\n",
            "Epoch: 2/15Batch 400/586Loss: 7.94948027760256e-06\n",
            "Epoch: 2/15Batch 450/586Loss: 6.079593731556088e-05\n",
            "Epoch: 2/15Batch 500/586Loss: 5.2263535508245695e-06\n",
            "Epoch: 2/15Batch 550/586Loss: 1.6409567251685075e-06\n",
            "training accuracy: 50.00%\n",
            "valid accuracy: 50.00%\n",
            "Epoch: 3/15Batch 0/586Loss: 15.714057922363281\n",
            "Epoch: 3/15Batch 50/586Loss: 0.0007991864113137126\n",
            "Epoch: 3/15Batch 100/586Loss: 2.1429987100418657e-05\n",
            "Epoch: 3/15Batch 150/586Loss: 7.70113110775128e-05\n",
            "Epoch: 3/15Batch 200/586Loss: 4.316003469284624e-05\n",
            "Epoch: 3/15Batch 250/586Loss: 4.6046417992329225e-05\n",
            "Epoch: 3/15Batch 300/586Loss: 3.425668716430664\n",
            "Epoch: 3/15Batch 350/586Loss: 0.004229390062391758\n",
            "Epoch: 3/15Batch 400/586Loss: 0.001621267176233232\n",
            "Epoch: 3/15Batch 450/586Loss: 0.0014577159890905023\n",
            "Epoch: 3/15Batch 500/586Loss: 0.0007849058602005243\n",
            "Epoch: 3/15Batch 550/586Loss: 8.464869461022317e-05\n",
            "training accuracy: 50.81%\n",
            "valid accuracy: 50.67%\n",
            "Epoch: 4/15Batch 0/586Loss: 6.82506799697876\n",
            "Epoch: 4/15Batch 50/586Loss: 0.023041291162371635\n",
            "Epoch: 4/15Batch 100/586Loss: 0.0014901646645739675\n",
            "Epoch: 4/15Batch 150/586Loss: 0.0012296501081436872\n",
            "Epoch: 4/15Batch 200/586Loss: 0.00036954431561753154\n",
            "Epoch: 4/15Batch 250/586Loss: 2.9344053473323584e-05\n",
            "Epoch: 4/15Batch 300/586Loss: 1.0790698528289795\n",
            "Epoch: 4/15Batch 350/586Loss: 0.0040644253604114056\n",
            "Epoch: 4/15Batch 400/586Loss: 0.0009649487328715622\n",
            "Epoch: 4/15Batch 450/586Loss: 0.0008262312621809542\n",
            "Epoch: 4/15Batch 500/586Loss: 0.00019677412637975067\n",
            "Epoch: 4/15Batch 550/586Loss: 0.0002838865329977125\n",
            "training accuracy: 54.98%\n",
            "valid accuracy: 54.02%\n",
            "Epoch: 5/15Batch 0/586Loss: 3.895608425140381\n",
            "Epoch: 5/15Batch 50/586Loss: 0.0024820915423333645\n",
            "Epoch: 5/15Batch 100/586Loss: 0.00035538733936846256\n",
            "Epoch: 5/15Batch 150/586Loss: 0.0005018016090616584\n",
            "Epoch: 5/15Batch 200/586Loss: 0.00045145428157411516\n",
            "Epoch: 5/15Batch 250/586Loss: 0.0001599045644979924\n",
            "Epoch: 5/15Batch 300/586Loss: 0.2813189923763275\n",
            "Epoch: 5/15Batch 350/586Loss: 0.01061493344604969\n",
            "Epoch: 5/15Batch 400/586Loss: 0.0014951196499168873\n",
            "Epoch: 5/15Batch 450/586Loss: 0.0017095962539315224\n",
            "Epoch: 5/15Batch 500/586Loss: 0.0006584259099327028\n",
            "Epoch: 5/15Batch 550/586Loss: 0.0002380344521952793\n",
            "training accuracy: 62.80%\n",
            "valid accuracy: 60.93%\n",
            "Epoch: 6/15Batch 0/586Loss: 1.7190886735916138\n",
            "Epoch: 6/15Batch 50/586Loss: 0.0013490593992173672\n",
            "Epoch: 6/15Batch 100/586Loss: 0.00010190786997554824\n",
            "Epoch: 6/15Batch 150/586Loss: 0.0001730303920339793\n",
            "Epoch: 6/15Batch 200/586Loss: 0.0003732081095222384\n",
            "Epoch: 6/15Batch 250/586Loss: 0.0002322507498320192\n",
            "Epoch: 6/15Batch 300/586Loss: 0.10388887673616409\n",
            "Epoch: 6/15Batch 350/586Loss: 0.0024077759589999914\n",
            "Epoch: 6/15Batch 400/586Loss: 0.001409029122442007\n",
            "Epoch: 6/15Batch 450/586Loss: 0.0016636175569146872\n",
            "Epoch: 6/15Batch 500/586Loss: 0.0009221485815942287\n",
            "Epoch: 6/15Batch 550/586Loss: 0.0022597068455070257\n",
            "training accuracy: 75.25%\n",
            "valid accuracy: 71.87%\n",
            "Epoch: 7/15Batch 0/586Loss: 0.2729157507419586\n",
            "Epoch: 7/15Batch 50/586Loss: 0.000662461097817868\n",
            "Epoch: 7/15Batch 100/586Loss: 0.00034225801937282085\n",
            "Epoch: 7/15Batch 150/586Loss: 0.00035969229065813124\n",
            "Epoch: 7/15Batch 200/586Loss: 0.00024802895495668054\n",
            "Epoch: 7/15Batch 250/586Loss: 0.0012086068745702505\n",
            "Epoch: 7/15Batch 300/586Loss: 0.010209326632320881\n",
            "Epoch: 7/15Batch 350/586Loss: 0.0032419494818896055\n",
            "Epoch: 7/15Batch 400/586Loss: 0.0009873785311356187\n",
            "Epoch: 7/15Batch 450/586Loss: 0.0010570378508418798\n",
            "Epoch: 7/15Batch 500/586Loss: 0.0009477471467107534\n",
            "Epoch: 7/15Batch 550/586Loss: 0.000511391437612474\n",
            "training accuracy: 80.19%\n",
            "valid accuracy: 75.20%\n",
            "Epoch: 8/15Batch 0/586Loss: 0.06734376400709152\n",
            "Epoch: 8/15Batch 50/586Loss: 0.0005452958284877241\n",
            "Epoch: 8/15Batch 100/586Loss: 0.0001900321221910417\n",
            "Epoch: 8/15Batch 150/586Loss: 0.0001735700061544776\n",
            "Epoch: 8/15Batch 200/586Loss: 0.000130263069877401\n",
            "Epoch: 8/15Batch 250/586Loss: 0.0004097617347724736\n",
            "Epoch: 8/15Batch 300/586Loss: 0.017651792615652084\n",
            "Epoch: 8/15Batch 350/586Loss: 0.0026602325960993767\n",
            "Epoch: 8/15Batch 400/586Loss: 0.002426450839266181\n",
            "Epoch: 8/15Batch 450/586Loss: 0.0005383577081374824\n",
            "Epoch: 8/15Batch 500/586Loss: 0.0004375928547233343\n",
            "Epoch: 8/15Batch 550/586Loss: 0.00017552862118463963\n",
            "training accuracy: 80.75%\n",
            "valid accuracy: 75.52%\n",
            "Epoch: 9/15Batch 0/586Loss: 0.03403612598776817\n",
            "Epoch: 9/15Batch 50/586Loss: 0.00012062090536346659\n",
            "Epoch: 9/15Batch 100/586Loss: 2.2887637896928936e-05\n",
            "Epoch: 9/15Batch 150/586Loss: 0.00011113144864793867\n",
            "Epoch: 9/15Batch 200/586Loss: 0.00011249402450630441\n",
            "Epoch: 9/15Batch 250/586Loss: 0.00018569000530987978\n",
            "Epoch: 9/15Batch 300/586Loss: 0.008366725407540798\n",
            "Epoch: 9/15Batch 350/586Loss: 0.010307615622878075\n",
            "Epoch: 9/15Batch 400/586Loss: 0.0002997787669301033\n",
            "Epoch: 9/15Batch 450/586Loss: 0.0006419140845537186\n",
            "Epoch: 9/15Batch 500/586Loss: 0.00015295622870326042\n",
            "Epoch: 9/15Batch 550/586Loss: 0.0001597316440893337\n",
            "training accuracy: 82.58%\n",
            "valid accuracy: 76.91%\n",
            "Epoch: 10/15Batch 0/586Loss: 0.010322718881070614\n",
            "Epoch: 10/15Batch 50/586Loss: 0.0003341729461681098\n",
            "Epoch: 10/15Batch 100/586Loss: 1.7265090718865395e-05\n",
            "Epoch: 10/15Batch 150/586Loss: 8.860573143465444e-05\n",
            "Epoch: 10/15Batch 200/586Loss: 4.825188807444647e-05\n",
            "Epoch: 10/15Batch 250/586Loss: 3.043922333745286e-05\n",
            "Epoch: 10/15Batch 300/586Loss: 0.0035389068070799112\n",
            "Epoch: 10/15Batch 350/586Loss: 0.0038590338081121445\n",
            "Epoch: 10/15Batch 400/586Loss: 0.00016977565246634185\n",
            "Epoch: 10/15Batch 450/586Loss: 0.00040931074181571603\n",
            "Epoch: 10/15Batch 500/586Loss: 0.00012919427535962313\n",
            "Epoch: 10/15Batch 550/586Loss: 3.637864938355051e-05\n",
            "training accuracy: 83.13%\n",
            "valid accuracy: 77.09%\n",
            "Epoch: 11/15Batch 0/586Loss: 0.006815756671130657\n",
            "Epoch: 11/15Batch 50/586Loss: 0.014566677622497082\n",
            "Epoch: 11/15Batch 100/586Loss: 1.1386895494069904e-05\n",
            "Epoch: 11/15Batch 150/586Loss: 1.802066071832087e-05\n",
            "Epoch: 11/15Batch 200/586Loss: 1.4375837054103613e-05\n",
            "Epoch: 11/15Batch 250/586Loss: 5.723728008888429e-06\n",
            "Epoch: 11/15Batch 300/586Loss: 0.006067684385925531\n",
            "Epoch: 11/15Batch 350/586Loss: 0.0032439562492072582\n",
            "Epoch: 11/15Batch 400/586Loss: 0.0001811911497497931\n",
            "Epoch: 11/15Batch 450/586Loss: 0.0014801266370341182\n",
            "Epoch: 11/15Batch 500/586Loss: 0.00027382944244891405\n",
            "Epoch: 11/15Batch 550/586Loss: 2.224616036983207e-05\n",
            "training accuracy: 81.57%\n",
            "valid accuracy: 75.84%\n",
            "Epoch: 12/15Batch 0/586Loss: 0.026417111977934837\n",
            "Epoch: 12/15Batch 50/586Loss: 0.0001511945592937991\n",
            "Epoch: 12/15Batch 100/586Loss: 1.6670493323545088e-06\n",
            "Epoch: 12/15Batch 150/586Loss: 4.63393735117279e-06\n",
            "Epoch: 12/15Batch 200/586Loss: 6.3792126638873015e-06\n",
            "Epoch: 12/15Batch 250/586Loss: 2.955949184979545e-06\n",
            "Epoch: 12/15Batch 300/586Loss: 0.05250483378767967\n",
            "Epoch: 12/15Batch 350/586Loss: 0.1358484923839569\n",
            "Epoch: 12/15Batch 400/586Loss: 0.0008607075433246791\n",
            "Epoch: 12/15Batch 450/586Loss: 0.0003039786242879927\n",
            "Epoch: 12/15Batch 500/586Loss: 7.325275510083884e-05\n",
            "Epoch: 12/15Batch 550/586Loss: 2.901885636674706e-05\n",
            "training accuracy: 84.76%\n",
            "valid accuracy: 78.11%\n",
            "Epoch: 13/15Batch 0/586Loss: 0.003763939021155238\n",
            "Epoch: 13/15Batch 50/586Loss: 0.06550880521535873\n",
            "Epoch: 13/15Batch 100/586Loss: 4.395697942527477e-06\n",
            "Epoch: 13/15Batch 150/586Loss: 1.113789312512381e-05\n",
            "Epoch: 13/15Batch 200/586Loss: 9.567035704094451e-06\n",
            "Epoch: 13/15Batch 250/586Loss: 2.5796978206926724e-06\n",
            "Epoch: 13/15Batch 300/586Loss: 0.027492579072713852\n",
            "Epoch: 13/15Batch 350/586Loss: 0.0023795152083039284\n",
            "Epoch: 13/15Batch 400/586Loss: 8.207617793232203e-05\n",
            "Epoch: 13/15Batch 450/586Loss: 0.0004381375038065016\n",
            "Epoch: 13/15Batch 500/586Loss: 3.628084232332185e-05\n",
            "Epoch: 13/15Batch 550/586Loss: 1.679181877989322e-05\n",
            "training accuracy: 85.86%\n",
            "valid accuracy: 78.61%\n",
            "Epoch: 14/15Batch 0/586Loss: 0.003808996407315135\n",
            "Epoch: 14/15Batch 50/586Loss: 7.631404878338799e-05\n",
            "Epoch: 14/15Batch 100/586Loss: 3.8143855363159673e-06\n",
            "Epoch: 14/15Batch 150/586Loss: 7.84168662448792e-07\n",
            "Epoch: 14/15Batch 200/586Loss: 5.140877306075708e-07\n",
            "Epoch: 14/15Batch 250/586Loss: 4.22819113055084e-07\n",
            "Epoch: 14/15Batch 300/586Loss: 0.00431667547672987\n",
            "Epoch: 14/15Batch 350/586Loss: 0.0010086719412356615\n",
            "Epoch: 14/15Batch 400/586Loss: 1.0569879123067949e-05\n",
            "Epoch: 14/15Batch 450/586Loss: 6.667090929113328e-05\n",
            "Epoch: 14/15Batch 500/586Loss: 2.0010136722703464e-05\n",
            "Epoch: 14/15Batch 550/586Loss: 5.030819920648355e-06\n",
            "training accuracy: 84.81%\n",
            "valid accuracy: 77.86%\n",
            "Epoch: 15/15Batch 0/586Loss: 0.020749954506754875\n",
            "Epoch: 15/15Batch 50/586Loss: 0.019640376791357994\n",
            "Epoch: 15/15Batch 100/586Loss: 1.3689913203052129e-06\n",
            "Epoch: 15/15Batch 150/586Loss: 1.5552774357274757e-06\n",
            "Epoch: 15/15Batch 200/586Loss: 1.6782023521955125e-06\n",
            "Epoch: 15/15Batch 250/586Loss: 2.7939611868532666e-07\n",
            "Epoch: 15/15Batch 300/586Loss: 0.006737547926604748\n",
            "Epoch: 15/15Batch 350/586Loss: 0.00957389734685421\n",
            "Epoch: 15/15Batch 400/586Loss: 0.0002990122593473643\n",
            "Epoch: 15/15Batch 450/586Loss: 7.90294652688317e-05\n",
            "Epoch: 15/15Batch 500/586Loss: 2.4552326067350805e-05\n",
            "Epoch: 15/15Batch 550/586Loss: 8.745165541768074e-05\n",
            "training accuracy: 85.84%\n",
            "valid accuracy: 78.45%\n",
            "Test accuracy: 78.48%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "67GyqTb1tWBh",
        "fgPrTcT7A4ot",
        "mfEsRUWltf3Z",
        "JliFItSyJ7RS",
        "SlNh4d36NoZ7",
        "fRt8LyyvPsqC",
        "JRbaJT1XiXi6"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}